{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe9e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from evidently.presets import *\n",
    "from evidently.metrics import *\n",
    "from evidently import *\n",
    "\n",
    "from housing.logger import Logger\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class EvidentlyReportGenerator:\n",
    "    def __init__(self, reference_path, current_path, pred_train_path, pred_test_path, reports_dir):\n",
    "        self.reference_path = reference_path\n",
    "        self.current_path = current_path\n",
    "        self.pred_train_path = pred_train_path\n",
    "        self.pred_test_path = pred_test_path\n",
    "        self.reports_dir = reports_dir\n",
    "        os.makedirs(self.reports_dir, exist_ok=True)\n",
    "\n",
    "        self.logger = Logger(\n",
    "            \"./logs/model_monitoring.log\",\n",
    "            \"Initialized EvidentlyReportGenerator\",\n",
    "            \"w\"\n",
    "        )\n",
    "        self.logger.logging()\n",
    "\n",
    "        self.reference_data = pd.read_csv(self.reference_path)\n",
    "        self.current_data = pd.read_csv(self.current_path)\n",
    "        self.predictions_train = pd.read_csv(self.pred_train_path)\n",
    "        self.predictions_test = pd.read_csv(self.pred_test_path)\n",
    "\n",
    "    def generate_data_drift_report(self):\n",
    "        path = os.path.join(self.reports_dir, \"data_drift_report.html\")\n",
    "        report = Report([DataDriftPreset()])\n",
    "        report.run(reference_data=self.reference_data, current_data=self.current_data).save_html(path)\n",
    "        # report.save_html(path)\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Data Drift Report saved to {path}\", \"a\").logging()\n",
    "\n",
    "    def generate_data_summary_report(self):\n",
    "        path = os.path.join(self.reports_dir, \"data_summary_report.html\")\n",
    "        report = Report([DataSummaryPreset()])\n",
    "        report.run(reference_data=self.reference_data, current_data=self.current_data).save_html(path)\n",
    "        # report.save_html(path)\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Data Summary Report saved to {path}\", \"a\").logging()\n",
    "\n",
    "    def generate_text_eval_report(self):\n",
    "        path = os.path.join(self.reports_dir, \"text_evals.html\")\n",
    "        report = Report([TextEvals()])\n",
    "        report.run(reference_data=self.reference_data, current_data=self.current_data).save_html(path)\n",
    "        # report.save_html(path)\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Text Evals Report saved to {path}\", \"a\").logging()\n",
    "\n",
    "    def generate_value_stats_report(self):\n",
    "        cols = [\n",
    "            'housing_median_age', 'total_rooms', 'total_bedrooms',\n",
    "            'population', 'households', 'median_income',\n",
    "            'rooms_per_household', 'bedrooms_per_room', 'population_per_household'\n",
    "        ]\n",
    "        metrics = [ValueStats(column=c) for c in cols]\n",
    "        path = os.path.join(self.reports_dir, \"value_stat_report.html\")\n",
    "        report = Report(metrics)\n",
    "        report.run(reference_data=self.reference_data, current_data=self.current_data).save_html(path)\n",
    "        # report.save_html(path)\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Value Stats Report saved to {path}\", \"a\").logging()\n",
    "\n",
    "    def generate_column_analysis_report(self):\n",
    "        path = os.path.join(self.reports_dir, \"column_report.html\")\n",
    "        report = Report(metrics=[\n",
    "            ColumnCount(), RowCount(), DatasetMissingValueCount(),\n",
    "            DriftedColumnsCount(), ConstantColumnsCount(), DuplicatedColumnsCount(),\n",
    "            DuplicatedRowCount(), EmptyColumnsCount(), EmptyRowsCount()\n",
    "        ])\n",
    "        report.run(reference_data=self.reference_data, current_data=self.current_data).save_html(path)\n",
    "        # report.save_html(path)\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Column Analysis Report saved to {path}\", \"a\").logging()\n",
    "\n",
    "    def log_missing_values(self):\n",
    "        reference_missing = self.reference_data.isnull().sum()\n",
    "        current_missing = self.current_data.isnull().sum()\n",
    "\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Missing values in reference data:\\n{reference_missing}\", \"a\").logging()\n",
    "        Logger(\"./logs/model_monitoring.log\", f\"Missing values in current data:\\n{current_missing}\", \"a\").logging()\n",
    "\n",
    "    def generate_model_performance_reports(self):\n",
    "        y_true_train = self.predictions_train[\"actual\"]\n",
    "        y_true_test = self.predictions_test[\"actual\"]\n",
    "\n",
    "        for model_name in self.predictions_train.columns[1:]:\n",
    "            y_pred_train = self.predictions_train[model_name]\n",
    "            y_pred_test = self.predictions_test[model_name]\n",
    "\n",
    "            performance_data_train = pd.DataFrame({\n",
    "                \"target\": y_true_train,\n",
    "                \"prediction\": y_pred_train\n",
    "            })\n",
    "\n",
    "            performance_data_test = pd.DataFrame({\n",
    "                \"target\": y_true_test,\n",
    "                \"prediction\": y_pred_test\n",
    "            })\n",
    "\n",
    "            data_definition = DataDefinition(\n",
    "                numerical_columns=[\"target\", \"prediction\"],\n",
    "                regression=[Regression(target=\"target\", prediction=\"prediction\")]\n",
    "            )\n",
    "\n",
    "            dataset_train = Dataset.from_pandas(performance_data_train, data_definition=data_definition)\n",
    "            dataset_test = Dataset.from_pandas(performance_data_test, data_definition=data_definition)\n",
    "\n",
    "            report = Report(metrics=[RegressionPreset()])\n",
    "            report_path = os.path.join(self.reports_dir, f\"{model_name}_performance_report.html\")\n",
    "            report.run(reference_data=dataset_train, current_data=dataset_test).save_html(report_path)\n",
    "            # report.save_html(report_path)\n",
    "\n",
    "            Logger(\"./logs/model_monitoring.log\", f\"{model_name} model performance report saved to {report_path}\", \"a\").logging()\n",
    "\n",
    "    def run_all(self):\n",
    "        self.generate_data_drift_report()\n",
    "        self.generate_data_summary_report()\n",
    "        self.generate_text_eval_report()\n",
    "        self.generate_value_stats_report()\n",
    "        self.generate_column_analysis_report()\n",
    "        self.log_missing_values()\n",
    "        self.generate_model_performance_reports()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77996d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generator = EvidentlyReportGenerator(\n",
    "        reference_path=\"/mnt/d/fsds_aws/data/processed/train/housing_train_processed.csv\",\n",
    "        current_path=\"/mnt/d/fsds_aws/data/processed/test/housing_test_processed.csv\",\n",
    "        pred_train_path=\"/mnt/d/fsds_aws/data/processed/train/model_predictions.csv\",\n",
    "        pred_test_path=\"/mnt/d/fsds_aws/data/processed/test/model_predictions.csv\",\n",
    "        reports_dir=\"/mnt/d/fsds_aws/reports\"\n",
    "    )\n",
    "\n",
    "    generator.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00a3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
